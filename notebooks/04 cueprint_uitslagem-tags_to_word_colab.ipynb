{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fa193133",
   "metadata": {},
   "source": [
    "# Cue Print tags → Word (.docx)\n",
    "\n",
    "Dit Colab-notebook zet een `.txt` met tags om naar een Word-document (`.docx`).\n",
    "\n",
    "**Regels (zoals afgesproken):**\n",
    "- `<subhead_lead>` (divisie/klasse) komt **1x** als kop (BOLD + UPPERCASE).\n",
    "- Daarna volgen alle wedstrijden (`<subhead>`) als **1 alinea per wedstrijd**.\n",
    "- Facts (`<howto_facts>`) worden **altijd italic** als er tekst is, op een nieuwe regel met **Shift+Enter** (soft line break).\n",
    "- Lege `<howto_facts>`: **overslaan**.\n",
    "- Tussen competitieblokken: **1 lege alinea**.\n",
    "- Output toont alleen **technische tellingen** (geen inhoud logging).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3076e9fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip -q install python-docx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "033861f3",
   "metadata": {},
   "source": [
    "## 1) Upload je bronbestand (.txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62226a6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import files\n",
    "\n",
    "uploaded = files.upload()\n",
    "if not uploaded:\n",
    "    raise ValueError(\"Geen bestand geüpload.\")\n",
    "\n",
    "INPUT_PATH = next(iter(uploaded.keys()))\n",
    "print(\"Inputbestand ontvangen.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a907f5f7",
   "metadata": {},
   "source": [
    "## 2) Parse: tags → tokens → items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc12807b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from dataclasses import dataclass\n",
    "from typing import List, Optional\n",
    "\n",
    "TAG_PATTERN = re.compile(r\"<(subhead_lead|subhead|howto_facts)>(.*?)</\\1>\", re.DOTALL | re.IGNORECASE)\n",
    "\n",
    "@dataclass\n",
    "class Token:\n",
    "    kind: str\n",
    "    text: str\n",
    "\n",
    "def extract_tokens(raw: str) -> List[Token]:\n",
    "    tokens: List[Token] = []\n",
    "    for m in TAG_PATTERN.finditer(raw):\n",
    "        kind = m.group(1).lower().strip()\n",
    "        text = (m.group(2) or \"\").replace(\"\\r\\n\", \"\\n\").replace(\"\\r\", \"\\n\").strip()\n",
    "        tokens.append(Token(kind=kind, text=text))\n",
    "    return tokens\n",
    "\n",
    "@dataclass\n",
    "class Item:\n",
    "    header: str\n",
    "    subhead: str\n",
    "    facts: Optional[str]  # None = geen facts / leeg\n",
    "\n",
    "def tokens_to_items(tokens: List[Token]) -> List[Item]:\n",
    "    items: List[Item] = []\n",
    "    current_header: Optional[str] = None\n",
    "    i = 0\n",
    "\n",
    "    while i < len(tokens):\n",
    "        t = tokens[i]\n",
    "\n",
    "        if t.kind == \"subhead_lead\":\n",
    "            current_header = t.text\n",
    "            i += 1\n",
    "            continue\n",
    "\n",
    "        if t.kind == \"subhead\":\n",
    "            if not current_header:\n",
    "                i += 1\n",
    "                continue\n",
    "\n",
    "            subhead_text = t.text\n",
    "            facts_text: Optional[str] = None\n",
    "\n",
    "            if i + 1 < len(tokens) and tokens[i + 1].kind == \"howto_facts\":\n",
    "                candidate = (tokens[i + 1].text or \"\").strip()\n",
    "                if candidate:\n",
    "                    facts_text = candidate\n",
    "                i += 2\n",
    "            else:\n",
    "                i += 1\n",
    "\n",
    "            items.append(Item(header=current_header, subhead=subhead_text, facts=facts_text))\n",
    "            continue\n",
    "\n",
    "        i += 1\n",
    "\n",
    "    return items\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89ae85ef",
   "metadata": {},
   "source": [
    "## 3) Bouw Word-document (.docx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95462ca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from docx import Document\n",
    "from docx.enum.text import WD_BREAK\n",
    "from typing import Dict\n",
    "\n",
    "def build_docx(items: List[Item], output_path: str) -> Dict[str, int]:\n",
    "    doc = Document()\n",
    "\n",
    "    stats = {\n",
    "        \"headers_total\": 0,\n",
    "        \"items_total\": 0,\n",
    "        \"items_with_facts\": 0,\n",
    "        \"empty_facts_skipped\": 0,\n",
    "        \"block_separators_added\": 0,\n",
    "    }\n",
    "\n",
    "    prev_header: Optional[str] = None\n",
    "\n",
    "    for it in items:\n",
    "        header = (it.header or \"\").strip()\n",
    "\n",
    "        if header and header != prev_header:\n",
    "            if prev_header is not None:\n",
    "                doc.add_paragraph(\"\")\n",
    "                stats[\"block_separators_added\"] += 1\n",
    "\n",
    "            hp = doc.add_paragraph()\n",
    "            hr = hp.add_run(header.upper())\n",
    "            hr.bold = True\n",
    "            stats[\"headers_total\"] += 1\n",
    "            prev_header = header\n",
    "\n",
    "        p = doc.add_paragraph()\n",
    "        r1 = p.add_run((it.subhead or \"\").strip())\n",
    "\n",
    "        facts = (it.facts or \"\").strip()\n",
    "        if facts:\n",
    "            r1.add_break(WD_BREAK.LINE)  # Shift+Enter\n",
    "            r2 = p.add_run(facts)\n",
    "            r2.italic = True\n",
    "            stats[\"items_with_facts\"] += 1\n",
    "        else:\n",
    "            stats[\"empty_facts_skipped\"] += 1\n",
    "\n",
    "        stats[\"items_total\"] += 1\n",
    "\n",
    "    doc.save(output_path)\n",
    "    return stats\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c78f34f4",
   "metadata": {},
   "source": [
    "## 4) Run + download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceb60dad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import files\n",
    "from collections import Counter\n",
    "from datetime import datetime\n",
    "\n",
    "with open(INPUT_PATH, \"r\", encoding=\"utf-8\", errors=\"replace\") as f:\n",
    "    raw = f.read()\n",
    "\n",
    "tokens = extract_tokens(raw)\n",
    "items = tokens_to_items(tokens)\n",
    "\n",
    "date = datetime.now().strftime(\"%Y%m%d\")\n",
    "OUTPUT_PATH = f\"{date}_cue_word_uitslagen_amateurs.docx\"\n",
    "\n",
    "stats = build_docx(items, OUTPUT_PATH)\n",
    "\n",
    "print(\"Klaar.\")\n",
    "print(f\"- Tokens gevonden: {len(tokens)}\")\n",
    "print(f\"- Tag verdeling: {dict(Counter(t.kind for t in tokens))}\")\n",
    "print(f\"- Koppen geplaatst: {stats['headers_total']}\")\n",
    "print(f\"- Items gemaakt: {stats['items_total']}\")\n",
    "print(f\"- Items met facts: {stats['items_with_facts']}\")\n",
    "print(f\"- Items zonder facts (overgeslagen): {stats['empty_facts_skipped']}\")\n",
    "print(f\"- Lege alinea's tussen blokken: {stats['block_separators_added']}\")\n",
    "print(f\"- Outputbestand: {OUTPUT_PATH}\")\n",
    "\n",
    "files.download(OUTPUT_PATH)\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "cueprint_tags_to_word.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
